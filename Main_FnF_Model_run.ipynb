{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from data_loader import *\n",
    "from  AL_strategies import *\n",
    "from models import *\n",
    "from metrics import *\n",
    "from Stream_Bootstrap_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "label_list = ['Sad or depressed', 'Calm or peaceful', 'Stressed or anxious', 'sleep_class', 'Angry or frustrated']\n",
    "output_folder = 'Dataset/FnF'\n",
    "\n",
    "# Load the data for each label\n",
    "data_dict = load_X_y_graphs(dataset='FnF, output_folder=Dataset/FnF')\n",
    "\n",
    "# Retrieving data for \"Sad or depressed\"\n",
    "X_sad = data_dict['Sad or depressed']['X']\n",
    "y_sad = data_dict['Sad or depressed']['y']\n",
    "L_friend_sad = data_dict['Sad or depressed']['L_friend']\n",
    "\n",
    "# Retrieving data for \"Stressed or anxious\"\n",
    "X_stress = data_dict['Stressed or anxious']['X']\n",
    "y_stress = data_dict['Stressed or anxious']['y']\n",
    "L_friend_stress = data_dict['Stressed or anxious']['L_friend']\n",
    "\n",
    "# Retrieving data for \"sleep_class\"\n",
    "X_sleep = data_dict['sleep_class']['X']\n",
    "y_sleep = data_dict['sleep_class']['y']\n",
    "L_friend_sleep = data_dict['sleep_class']['L_friend']\n",
    "\n",
    "# Retrieving data for \"Angry or frustrated\"\n",
    "X_angry = data_dict['Angry or frustrated']['X']\n",
    "y_angry = data_dict['Angry or frustrated']['y']\n",
    "L_friend_angry = data_dict['Angry or frustrated']['L_friend']\n",
    "\n",
    "# Retrieving data for \"Calm or peaceful\"\n",
    "X_calm = data_dict['Calm or peaceful']['X']\n",
    "y_calm = data_dict['Calm or peaceful']['y']\n",
    "L_friend_calm = data_dict['Calm or peaceful']['L_friend']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## A function to run all AL stratgies and save the results \n",
    "def evaluate_and_plot_all_strategies_with_uncertainty(X, y, A, num_days, num_nodes, num_features, L, k, model_class,\n",
    "                                                      metrics_list, n_bootstraps, dynamic_A, num_classes, train_mask,\n",
    "                                                      test_mask, seed=None, save_folder=\"results\", model_params=None):\n",
    "    all_metrics_df = []  # To collect metrics for all strategies\n",
    "\n",
    "    # Set up a folder for consolidated metrics and user logs\n",
    "    metrics_folder = os.path.join(save_folder, \"metrics\")\n",
    "    os.makedirs(metrics_folder, exist_ok=True)\n",
    "\n",
    "    # Define strategies including each uncertainty variant and the 'no_AL' strategy\n",
    "    strategies = ['graphpart', 'graphpartfar', 'age', 'coreset', 'featProp', \"density\",\n",
    "                  \"uncertainty_entropy\", \"uncertainty_least_confidence\", \"uncertainty_margin\",\n",
    "                  \"pagerank\", \"degree\", \"random_sample\", \"no_AL\"]\n",
    "\n",
    "    # Map uncertainty strategy names to the actual metric used in uncertainty_strategy\n",
    "    uncertainty_strategies = {\n",
    "        \"uncertainty_entropy\": \"entropy\",\n",
    "        \"uncertainty_least_confidence\": \"least_confidence\",\n",
    "        \"uncertainty_margin\": \"margin\"\n",
    "    }\n",
    "\n",
    "    for strategy in strategies:\n",
    "        print(f\"Running bootstrap and evaluation for strategy: {strategy}\")\n",
    "        \n",
    "        # Adjust strategy and k for 'no_AL'\n",
    "        if strategy == 'no_AL':\n",
    "            current_strategy =  \"random_sample\"\n",
    "            current_k = 0\n",
    "        else:\n",
    "            current_strategy = strategy\n",
    "            current_k = k\n",
    "\n",
    "        # Determine if the current strategy is an uncertainty-based one\n",
    "        if current_strategy.startswith(\"uncertainty\"):\n",
    "            # Set the uncertainty metric from the mapping\n",
    "            uncertainty_metric = uncertainty_strategies[current_strategy]\n",
    "            metrics_df = bootstrap_and_evaluate(\n",
    "                X=X, y=y, A=A, num_days=num_days, num_nodes=num_nodes, num_features=num_features,\n",
    "                L=L, k=current_k, model_class=model_class, strategy=\"uncertainty\", uncertainity_metric=uncertainty_metric,\n",
    "                metrics_list=metrics_list, n_bootstraps=n_bootstraps, dynamic_A=dynamic_A,\n",
    "                num_classes=num_classes, train_mask=train_mask, test_mask=test_mask, seed=seed,\n",
    "                save_folder=save_folder, model_params=model_params  # Pass model_params here\n",
    "            )\n",
    "        else:\n",
    "            # For non-uncertainty strategies including 'no_AL' which uses 'random'\n",
    "            metrics_df = bootstrap_and_evaluate(\n",
    "                X=X, y=y, A=A, num_days=num_days, num_nodes=num_nodes, num_features=num_features,\n",
    "                L=L, k=current_k, model_class=model_class, strategy=current_strategy, uncertainity_metric=None,\n",
    "                metrics_list=metrics_list, n_bootstraps=n_bootstraps, dynamic_A=dynamic_A,\n",
    "                num_classes=num_classes, train_mask=train_mask, test_mask=test_mask, seed=seed,\n",
    "                save_folder=save_folder, model_params=model_params  # Pass model_params here\n",
    "            )\n",
    "\n",
    "        # Add strategy as a column in the metrics DataFrame\n",
    "        metrics_df[\"strategy\"] = strategy  # Keep original strategy name for clarity\n",
    "        all_metrics_df.append(metrics_df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    consolidated_df = pd.concat(all_metrics_df, ignore_index=True)\n",
    "\n",
    "    # Save the consolidated metrics DataFrame for all strategies in the metrics folder\n",
    "    consolidated_metrics_path = os.path.join(metrics_folder, \"consolidated_metrics_all_strategies_with_baselines.csv\")\n",
    "    consolidated_df.to_csv(consolidated_metrics_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define label data structure\n",
    "data_dict = {\n",
    "    'Calm or peaceful': {'X': X_calm, 'y': y_calm, 'L_friend': L_friend_calm},\n",
    "    # 'Sad or depressed': {'X': X_sad, 'y': y_sad, 'L_friend': L_friend_sad},\n",
    "    # 'Stressed or anxious': {'X': X_stress, 'y': y_stress, 'L_friend': L_friend_stress},\n",
    "    # 'Angry or frustrated': {'X': X_angry, 'y': y_angry, 'L_friend': L_friend_angry},\n",
    "\n",
    "}\n",
    "\n",
    "# Define graph types\n",
    "graph_types = ['L_friend', 'L_duration', 'L_non_zero', 'L_couple']\n",
    "\n",
    "# Define values for L and k to iterate over\n",
    "L_values = [2,4,6,8,10]  # Example values for L\n",
    "k_values = [2, 4, 6,8, 10]    # Example values for k\n",
    "\n",
    "# Model and experiment parameters\n",
    "num_classes = 2\n",
    "metrics_list = ['accuracy', 'precision', 'recall', 'roc_auc', 'pr_auc', 'f1_micro', 'f1_macro']\n",
    "n_bootstraps = 100\n",
    "dynamic_A = False\n",
    "train_ratio = 0.8\n",
    "model_class = GATModel\n",
    "model_params = {\n",
    "    'hidden_channels': 64,\n",
    "    'num_heads': 8,\n",
    "    'num_layers': 2,\n",
    "    'dropout': 0.7,\n",
    "    'activation': \"relu\",\n",
    "    'batchnorm': True\n",
    "}\n",
    "seed = 42\n",
    "\n",
    "# Main folder for results\n",
    "base_folder = \"Results_FnF\"\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Run experiments for each label, graph type, and (L, k) combination\n",
    "for label, data in data_dict.items():\n",
    "    label_folder = os.path.join(base_folder, label)\n",
    "    os.makedirs(label_folder, exist_ok=True)\n",
    "    \n",
    "    for graph_type in graph_types:\n",
    "        graph_folder = os.path.join(label_folder, graph_type)\n",
    "        os.makedirs(graph_folder, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        for L in L_values:\n",
    "            for k in k_values:\n",
    "                subfolder_name = f\"L_{L}_k_{k}\"\n",
    "                experiment_folder = os.path.join(graph_folder, subfolder_name)\n",
    "                os.makedirs(experiment_folder, exist_ok=True)\n",
    "                # Print the current configuration being processed\n",
    "                print(f\"Processing Label: {label}, Graph: {graph_type}, L: {L}, k: {k}\")\n",
    "                \n",
    "                \n",
    "                # Prepare inputs for the current label and graph type\n",
    "                X = data['X']\n",
    "                y = data['y']\n",
    "                A = data.get(graph_type, None)\n",
    "                \n",
    "                if A is None:\n",
    "                    continue  # Skip if the graph type is not found in the data\n",
    "                \n",
    "                num_days, num_nodes, num_features = X.shape\n",
    "                \n",
    "                # Generate train and test masks\n",
    "                train_mask, test_mask = generate_train_test_masks(num_nodes, train_ratio=train_ratio)\n",
    "                train_mask = torch.tensor(train_mask, dtype=torch.bool) if isinstance(train_mask, np.ndarray) else train_mask\n",
    "                test_mask = torch.tensor(test_mask, dtype=torch.bool) if isinstance(test_mask, np.ndarray) else test_mask\n",
    "                \n",
    "                # Run experiment\n",
    "                evaluate_and_plot_all_strategies_with_uncertainty(\n",
    "                    X, y, A, num_days, num_nodes, num_features, L, k, model_class,\n",
    "                    metrics_list, n_bootstraps, dynamic_A, num_classes, train_mask,\n",
    "                    test_mask, seed=seed, save_folder=experiment_folder, model_params=model_params\n",
    "                )\n",
    "\n",
    "                # Free up memory after each iteration\n",
    "                del X, y, A, train_mask, test_mask\n",
    "               \n",
    "\n",
    "print(\"All experiments completed and results saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
